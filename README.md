# ğŸŒ™ Echoes of Forgotten Whispers

A living dream chamber where your feelings never truly vanish â€” they decay, distort, and return as haunted whispers. Built with Next.js, p5.js, ElevenLabs, and Hugging Face.

**Dream Fragments:** Emotional Memory â€¢ Voice of the Machine â€¢ Temporal Shifts

## âœ¨ Features

- **Living Canvas**: Memory orbs that pulse, attract, and repel based on emotions
- **Emotion Analysis**: AI-powered emotion detection using Hugging Face
- **Voice Synthesis**: Haunting whispers generated by ElevenLabs AI
- **Voice Input**: Speak your memories using Web Speech API
- **Temporal Decay**: Memories slowly fade and distort over time
- **Rare Events**:
  - **Memory Bleed**: All whispers play at once when 15+ memories exist
  - **Forgiveness**: Type "I forgive" or "let go" to dissolve all memories in light
  - **The Void Calls**: After 5 minutes of silence, a black orb appears
- **Constellation Mode**: Connections appear between similar emotions
- **Persistent Storage**: Memories survive browser sessions
- **Mobile Responsive**: Full touch support with device motion reactions

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
cd echoes-of-forgotten-whispers
npm install
```

### 2. Set Up API Keys

Copy the environment template:

```bash
cp .env.local.example .env.local
```

Edit `.env.local` with your API keys:

#### Get ElevenLabs API Key (Voice Synthesis)
1. Go to https://elevenlabs.io/
2. Sign up (free tier: 10,000 characters/month)
3. Navigate to Settings â†’ API Keys â†’ Generate
4. Copy your API key to `.env.local`

**Optional: Create Custom Voice**
1. Go to Voice Lab â†’ Voice Design
2. Set Stability: 0.3, Similarity: 0.4 (creates ghostly effect)
3. Name it "Erynn" or "The Echo"
4. Copy the Voice ID to `.env.local`

#### Get Hugging Face API Key (Emotion Analysis)
1. Go to https://huggingface.co/
2. Sign up (completely free)
3. Go to Settings â†’ Access Tokens â†’ New Token
4. Create with "Read" permissions
5. Copy your token to `.env.local`

**Note:** The app works without API keys using fallback mechanisms:
- Emotion analysis uses local keyword-based detection
- Voice synthesis is disabled (silent mode)

### 3. Run Development Server

```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) in your browser.

## ğŸ“¦ Tech Stack

- **Framework**: Next.js 16 (App Router) with TypeScript
- **Visualization**: p5.js for living particle landscape
- **State Management**: Zustand with localStorage persistence
- **Animations**: Framer Motion
- **Styling**: Tailwind CSS v4
- **AI Services**:
  - Hugging Face Inference API (emotion analysis)
  - ElevenLabs API (voice synthesis)
- **Audio**: Native Web Audio API
- **Voice Input**: Web Speech API

## ğŸ¨ How It Works

### Memory Creation Flow
1. User inputs text or speaks a memory
2. Text is analyzed for emotion (joy, sadness, anger, fear, love, neutral)
3. Memory orb appears on canvas with emotion-specific color
4. AI generates whispered audio echo (if ElevenLabs configured)
5. Memory slowly decays over time

### Emotion Colors
- **Joy**: Gold `#FFD700`
- **Sadness**: Deep Blue `#4A90E2`
- **Anger**: Crimson `#E74C3C`
- **Fear**: Purple `#9B59B6`
- **Love**: Soft Pink `#FF69B4`
- **Neutral**: Grey `#95A5A6`

### Physics System
- Orbs attract similar emotions
- Orbs repel different emotions
- Mouse/touch creates gravity wells
- Boundaries have soft bounce
- Heartbeat pulse syncs all orbs

### Temporal Decay
- Each memory starts with decay = 1.0
- Decay decreases by 0.0002 per frame (~60fps)
- Low decay triggers glitch effects
- Old memories randomly resurrect as distorted whispers

## ğŸ­ Rare Events

### Memory Bleed
**Trigger**: 15+ memories exist
**Effect**: All memories blur together, whispers overlap

### Forgiveness
**Trigger**: Type "I forgive", "let go", or "release"
**Effect**: All memories dissolve into brilliant light over 3 seconds

### The Void Calls
**Trigger**: 5 minutes of inactivity
**Effect**: Black orb appears asking "Do you still remember me?"

## ğŸ› ï¸ Project Structure

```
echoes-of-forgotten-whispers/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ analyze-emotion/route.ts    # Emotion analysis endpoint
â”‚   â”‚   â””â”€â”€ generate-voice/route.ts     # Voice synthesis endpoint
â”‚   â”œâ”€â”€ layout.tsx                       # Root layout with metadata
â”‚   â”œâ”€â”€ page.tsx                         # Main experience page
â”‚   â””â”€â”€ globals.css                      # Dark theme + animations
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ Canvas.tsx                       # p5.js living canvas
â”‚   â”œâ”€â”€ InputZone.tsx                    # Text/voice input
â”‚   â””â”€â”€ RareEvents.tsx                   # Special event triggers
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ types.ts                         # TypeScript interfaces
â”‚   â””â”€â”€ memoryStore.ts                   # Zustand state management
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ useVoiceInput.ts                 # Web Speech API hook
â””â”€â”€ public/                              # Static assets
```

## ğŸ“± Mobile Support

- Touch-friendly input
- Device motion affects orbs (tilt phone)
- Optimized particle count
- Responsive UI scaling
- Voice input on supported browsers

## ğŸš¢ Deployment

### Deploy to Vercel (Recommended)

1. Push to GitHub:
```bash
git init
git add .
git commit -m "Initial commit - Echoes of Forgotten Whispers"
git branch -M main
git remote add origin YOUR_GITHUB_REPO_URL
git push -u origin main
```

2. Go to [vercel.com](https://vercel.com)
3. Import your GitHub repository
4. Add environment variables in Vercel dashboard:
   - `ELEVENLABS_API_KEY`
   - `ELEVENLABS_VOICE_ID` (optional)
   - `HUGGINGFACE_API_KEY`
5. Deploy!

Your app will be live at `your-project.vercel.app`

## ğŸ¯ What You Need to Do

### Before Running:
1. âœ… Install dependencies (`npm install`)
2. âœ… Set up API keys in `.env.local` (optional but recommended)
3. âœ… Run development server (`npm run dev`)

### For Production:
1. Get API keys from ElevenLabs and Hugging Face
2. Test locally with `npm run dev`
3. Push to GitHub
4. Deploy on Vercel
5. Add environment variables in Vercel
6. Create demo video (2-3 minutes)

### Demo Video Suggestions:
- Start in silence, show empty canvas
- Type a sad memory â†’ watch orb appear + hear whisper
- Add happy memory â†’ show collision/interaction
- Wait for old memory to resurrect (distorted)
- Trigger "Forgiveness" for emotional finale
- Show mobile responsiveness

## ğŸ¬ Submission Description

```
Echoes of Forgotten Whispers

Dream Fragments: Emotional Memory â— Voice of the Machine â— Temporal Shifts

A living dream chamber where your feelings never truly vanish â€” they decay, 
distort, and return as haunted whispers. Each memory becomes a glowing orb 
that pulses with emotion, slowly fades over time, and occasionally resurrects 
in corrupted form. Built from scratch in 72 hours with Next.js, p5.js, 
ElevenLabs, and Hugging Face.

Try typing "I forgive" to experience the Forgiveness event.

Live Demo: [your-vercel-url]
GitHub: [your-github-url]
```

## ğŸ› Troubleshooting

### Voice Input Not Working
- Only works in Chrome/Edge (not Firefox/Safari)
- Requires HTTPS (localhost is fine)
- Check microphone permissions

### No Audio Playing
- Check ElevenLabs API key in `.env.local`
- Check browser console for errors
- Ensure audio autoplay is enabled
- Try user interaction first (click something)

### Orbs Not Appearing
- Check browser console for errors
- Verify Zustand store is working
- Try clearing localStorage

### API Rate Limits
- ElevenLabs free tier: 10,000 chars/month
- Hugging Face: Generous limits, may queue if busy
- Consider caching emotion results

## ğŸ“ License

MIT License - feel free to use for your hackathon and beyond!

## ğŸ™ Credits

Created for Dreamware Hack 2024
Built with passion, code, and a touch of melancholy

---

*"Your words become eternal whispers"* ğŸŒ™
